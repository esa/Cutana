{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutana Backend Demo\n",
    "\n",
    "This notebook demonstrates how to use the Cutana backend for astronomical image cutout processing.\n",
    "\n",
    "## Setup and Configuration\n",
    "\n",
    "First, let's import the necessary modules and configure logging to see what's happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path().parent))\n",
    "import cutana\n",
    "# Configure logging for Jupyter\n",
    "logger.remove()  # Remove default handler\n",
    "logger.add(sys.stdout, level=\"INFO\", format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} - {message}\")\n",
    "logger.add(\"../logs/cutana_demo.log\", level=\"DEBUG\", format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} - {message}\")\n",
    "\n",
    "print(\"‚úÖ Imports and logging configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data\n",
    "\n",
    "We'll use the mock test data that includes proper file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source catalogue - use the Euclid-compliant mock data\n",
    "# first generate the test data using calling generate_test_data.py\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Generate test data first\n",
    "print(\"üì¶ Generating test data...\")\n",
    "try:\n",
    "    result = subprocess.run([\n",
    "        sys.executable, \"../tests/test_data/generate_test_data.py\", \"--size\", \"small\"\n",
    "    ], capture_output=True, text=True, cwd=Path.cwd())\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Test data generated successfully\")\n",
    "        if result.stdout:\n",
    "            print(result.stdout)\n",
    "    else:\n",
    "        print(f\"‚ùå Error generating test data: {result.stderr}\")\n",
    "        raise Exception(f\"Test data generation failed: {result.stderr}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error running generate_test_data.py: {e}\")\n",
    "    raise\n",
    "\n",
    "catalogue_path = \"../tests/test_data/euclid_cutana_catalogue_small.csv\"\n",
    "print(f\"Loading catalogue from: {catalogue_path}\")\n",
    "\n",
    "try:\n",
    "    catalogue = pd.read_csv(catalogue_path)\n",
    "    print(f\"‚úÖ Loaded {len(catalogue)} sources\")\n",
    "    print(f\"Columns: {list(catalogue.columns)}\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"\\nFirst 3 sources:\")\n",
    "    display(catalogue.head(3))\n",
    "    \n",
    "    # Check if FITS files exist\n",
    "    first_fits_path = eval(catalogue.iloc[0]['fits_file_paths'])[0]\n",
    "    fits_exists = Path(first_fits_path).exists()\n",
    "    print(f\"\\nFITS file check: {first_fits_path}\")\n",
    "    print(f\"File exists: {fits_exists}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading catalogue: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Processing Parameters\n",
    "\n",
    "Let's create a robust configuration for processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "output_dir = Path(\"../examples/output\")\n",
    "logs_dir = Path(\"../logs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "logs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Configure processing with robust error handling\n",
    "\n",
    "config = get_default_config()\n",
    "config.fits_extensions= [\"PRIMARY\"],  # Use PRIMARY extension for mock data\n",
    "config.target_resolution= 64,\n",
    "config.file_type= \"float32\",\n",
    "config.stretch=\"linear\",\n",
    "    \n",
    "    # Workflow parameters - conservative for demo\n",
    "config.max_workers= 1,  # Single worker for clearer debugging\n",
    "    \n",
    "    # Output configuration\n",
    "config.output_format = \"zarr\"\n",
    "config.output_dir = str(output_dir)\n",
    "\n",
    "    # Logging and tracking\n",
    "config.log_level = \"INFO\"\n",
    "config.workflow_file = str(output_dir / \"workflow_state.json\")\n",
    "config.tracking_file = str(output_dir / \"tracking.json\")\n",
    "\n",
    "print(\"üìã Configuration:\")\n",
    "print(json.dumps({k: v for k, v in config.items()}, indent=2))\n",
    "print(f\"\\n‚úÖ Output directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and Run Processing\n",
    "\n",
    "Now let's create the orchestrator and start processing with comprehensive error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize orchestrator\n",
    "    print(\"üöÄ Initializing Cutana orchestrator...\")\n",
    "    orchestrator = Orchestrator(config)\n",
    "    \n",
    "    # Use only first 5 sources for demo\n",
    "    demo_catalogue = catalogue.head(5).copy()\n",
    "    print(f\"\\nüìä Processing {len(demo_catalogue)} sources for demo...\")\n",
    "    \n",
    "    # Start processing with detailed monitoring\n",
    "    print(\"‚è≥ Starting cutout processing...\")\n",
    "    print(\"This may take a few minutes. Watch the logs above for progress.\")\n",
    "    \n",
    "    results = orchestrator.start_processing(demo_catalogue)\n",
    "    \n",
    "    print(f\"\\nüéâ Processing completed!\")\n",
    "    print(f\"Status: {results['status']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error during processing: {e}\")\n",
    "    logger.exception(\"Detailed error information:\")\n",
    "    \n",
    "    # Print last few lines from log file for debugging\n",
    "    log_file = Path(\"../logs/cutana_demo.log\")\n",
    "    if log_file.exists():\n",
    "        print(\"\\nüìã Last 20 lines from log file:\")\n",
    "        with open(log_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[-20:]:\n",
    "                print(line.strip())\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Results\n",
    "\n",
    "Let's examine what was produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check processing results\n",
    "if 'results' in locals() and results['status'] == 'completed':\n",
    "    print(\"üìà Processing Summary:\")\n",
    "    print(f\"- Total sources: {results['total_sources']}\")\n",
    "    print(f\"- Completed batches: {results['completed_batches']}\")\n",
    "    \n",
    "    # Check output files\n",
    "    zarr_files = list(output_dir.glob(\"*.zarr\"))\n",
    "    fits_files = list(output_dir.glob(\"*.fits\"))\n",
    "    json_files = list(output_dir.glob(\"*.json\"))\n",
    "    \n",
    "    print(f\"\\nüìÅ Output files created:\")\n",
    "    print(f\"- Zarr archives: {len(zarr_files)}\")\n",
    "    print(f\"- FITS files: {len(fits_files)}\")\n",
    "    print(f\"- JSON metadata: {len(json_files)}\")\n",
    "    \n",
    "    if zarr_files:\n",
    "        print(\"\\nüì¶ Zarr files:\")\n",
    "        for zarr_file in zarr_files:\n",
    "            size_mb = zarr_file.stat().st_size / (1024*1024)\n",
    "            print(f\"  - {zarr_file.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    # Check progress tracking\n",
    "    progress = orchestrator.get_progress()\n",
    "    print(f\"\\nüìä Final progress: {progress.get('progress_percent', 0):.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Processing did not complete successfully\")\n",
    "    if 'results' in locals():\n",
    "        print(f\"Status: {results.get('status', 'unknown')}\")\n",
    "        if 'error' in results:\n",
    "            print(f\"Error: {results['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Information\n",
    "\n",
    "If something went wrong, let's gather debug information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug information\n",
    "print(\"üîç Debug Information:\")\n",
    "print(f\"- Working directory: {Path.cwd()}\")\n",
    "print(f\"- Output directory exists: {output_dir.exists()}\")\n",
    "print(f\"- Log file exists: {Path('../logs/cutana_demo.log').exists()}\")\n",
    "\n",
    "# Check if any subprocess files were created\n",
    "temp_files = list(output_dir.glob(\"cutout*\"))\n",
    "if temp_files:\n",
    "    print(f\"\\nüìÑ Temporary/process files found:\")\n",
    "    for temp_file in temp_files:\n",
    "        print(f\"  - {temp_file.name}\")\n",
    "\n",
    "# Show system info\n",
    "import psutil\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"\\nüíª System Resources:\")\n",
    "print(f\"- CPU cores: {psutil.cpu_count()}\")\n",
    "print(f\"- Memory: {memory.total / (1024**3):.1f} GB total, {memory.available / (1024**3):.1f} GB available\")\n",
    "print(f\"- Python version: {sys.version}\")\n",
    "\n",
    "print(\"\\n‚úÖ Demo completed! Check the logs and output files for detailed results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import images_to_zarr as i2z\n",
    "\n",
    "i2z.inspect(\"output/images.zarr\")\n",
    "# i2z.display_sample_images(\"output/images.zarr\")\n",
    "\n",
    "# Display a specific image\n",
    "import zarr\n",
    "from matplotlib import pyplot as plt\n",
    "file = zarr.open(\"output/images.zarr\", mode='r')\n",
    "image = file['images'][3]\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import images_to_zarr as i2z\n",
    "\n",
    "i2z.inspect(\"../benchmarking/output/cutouts_cutout-process-15584_1754487403884154100.zarr/\")\n",
    "# i2z.display_sample_images(\"../benchmarking/output/cutouts_cutout-process-15584_1754487403884154100.zarr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a specific image\n",
    "import zarr\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "file = zarr.open(\"../benchmarking/output/batch_003/images.zarr\", mode='r')\n",
    "\n",
    "# Display 16 random images in a grid\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for ax in axes.flatten():\n",
    "    image = file['images'][np.random.randint(0, file['images'].shape[0])]\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cutana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
